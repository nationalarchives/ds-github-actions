# EBS playbook
---
- name: initialise EBS
  hosts: localhost
  gather_facts: true

  tasks:
  - name: check if subnet a
    set_fact:
      subnet_id: "{{ lookup( 'env', 'SUBNET_ID_A') }}"
    when: zone == "eu-west-2a"

  - name: check if subnet b
    set_fact:
      subnet_id: "{{ lookup( 'env', 'SUBNET_ID_B') }}"
    when: zone == "eu-west-2b"

  - name: switch role credentials
    community.aws.sts_assume_role:
      role_arn: "{{ role_arn }}"
      role_session_name: "s-devops-ebs-base"
    register: assumed_role

  - name: get linux 2023 AMI
    amazon.aws.ec2_ami_info:
      owners: amazon
      region: "{{ region }}"
      filters:
        name: "al2023-ami-2023*"
        architecture: "x86_64"
    register: findami

  - name: set latest AMI
    set_fact:
      latest_ami: >
        {{ findami.images | sort(attribute='creation_date') | last }}

  - name: create deployment policy
    amazon.aws.iam_managed_policy:
      policy_name: "ansible-ebs-{{ project_name }}-{{ function }}-policy"
      policy: "{{ lookup('file', './instance-role-policy.json') }}"
      state: "present"
    register: ebs_policy

  - name: EC2 IAM role
    community.aws.iam_role:
      name: "ansible-ebs-{{ project_name }}-{{ function }}-role"
      region: "{{ region }}"
      assume_role_policy_document: "{{ lookup('file', './ec2-role-policy.json') }}"
      managed_policies: ["{{ ebs_policy.policy.arn }}", "arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM"]
      create_instance_profile: yes
      delete_instance_profile: yes
      purge_policies: yes
      state: "present"
    register: ec2_iam_role

  - name: create security group - allowing updates and downloads
    amazon.aws.ec2_security_group:
      name: "ansible-ebs-{{ project_name }}-{{ function }}-sg"
      description: "security group allowing updates and downloads"
      region: "{{ region }}"
      vpc_id: "{{ lookup( 'env', 'VPC_ID') }}"
      rules:
        - proto: "tcp"
          from_port: 22
          to_port: 22
          cidr_ip: "0.0.0.0/0"
          rule_desc: "allow incoming ssh connections"
        - proto: "tcp"
          from_port: 1024
          to_port: 65535
          cidr_ip: "0.0.0.0/0"
          rule_desc: "for updates and downloads"
      rules_egress:
        - proto: "tcp"
          from_port: 80
          to_port: 80
          cidr_ip: "0.0.0.0/0"
          rule_desc: "allow updates and downloads"
        - proto: "tcp"
          from_port: 443
          to_port: 443
          cidr_ip: "0.0.0.0/0"
          rule_desc: "allow updates and downloads"
        - proto: "tcp"
          from_port: 1024
          to_port: 65535
          cidr_ip: "0.0.0.0/0"
          rule_desc: "allow replies"
      state: "present"
    register: ec2_sec_group

  - name: Create EBS volume
    amazon.aws.ec2_vol:
      zone: "{{ zone }}"
      multi_attach: false
      volume_size: "{{ ebs_size }}"
      volume_type: "{{ ebs_type }}"
      encrypted: "true"
      tags:
        Name: "{{ project_name }}-{{ function }}-data"
        CreatedAt: "{{ ansible_date_time.date }}-{{ ansible_date_time.hour }}:{{ ansible_date_time.minute }}:{{ ansible_date_time.second }}"
        snapshot: "true"
        db_type: "{{ db_type }}"
    register: ec2_vol

  - name: template userdata
    vars:
      region: "{{ region }}"
      volume_name: "{{ project_name }}-{{ function }}-data"
    template:
      src: "./templates/userdata.sh.j2"
      dest: "./userdata.sh"
      force: yes

  - name: provisioning temp instance
    amazon.aws.ec2_instance:
      key_name: "{{ key_name }}"
      image_id: "{{ latest_ami.image_id }}"#
      instance_role: "{{ ec2_iam_role.iam_role.role_name }}"
      instance_type: "t3a.small"
      metadata_options:
        http_tokens: "required"
      name : "ansible-ebs-temp-instance"
      network:
        assign_public_ip: yes
        delete_on_termination: yes
        subnet_id: "{{ lookup( 'env', 'SUBNET_ID') }}"
      region: "{{ region }}"
      security_groups: ["{{ ec2_sec_group.group_id }}"]
      state: "running"
      termination_protection: no
      user_data: "{{ lookup('file', './userdata.sh') }}"
      wait: true
      volumes:
        - device_name: "/dev/xvda"
          ebs:
            delete_on_termination: true
            encrypted: true
            volume_size: "40"
      vpc_subnet_id: "{{ subnet_id }}"
      tags:
        Environment: "{{ account }}"
        Service: "ansible-ebs-temp-instance"
        Owner: "Digital Services"
        CreatedBy: "ansible"
        CostCentre: 53
        Terraform: false
    register: ec2

  - name: get instance ip address
    set_fact:
      instance_private_ip: "{{ ec2.instances[0].private_ip_address }}"
      instance_public_ip: "{{ ec2.instances[0].public_ip_address }}"
      instance_id: "{{ ec2.instances[0].instance_id }}"

  - ansible.builtin.debug:
      msg:
        - "====================================================================="
        - "instance started up"
        - "instance private ip: {{ instance_private_ip }}"
        - "instance id: {{ instance_id }}"
        - "instance public ip {{ instance_public_ip }}"
        - "====================================================================="

  - name: register new ec2 as host
    ansible.builtin.add_host:
      hostname: "{{ instance_public_ip }}"
      groups: ec2hosts
      ansible_user: ec2-user
      remote_user: ec2-user
      gather_facts: no

  - name: wait for SSH service to bind on new instance
    wait_for:
      host: "{{ instance_public_ip }}"
      port: 22
      delay: 90
      timeout: 600
      state: started

- name: switch to ec2hosts
  hosts: ec2hosts
  gather_facts: false

  tasks:
  - ansible.builtin.debug:
      msg:
        - "====================================================================="
        - "checking status of new instance before ami can be build"
        - "20 second interval with max duration of 5 minutes"
        - "====================================================================="

  - name: check if ec2 instance is ready
    ansible.builtin.stat:
      path: "/var/finish-ebs.txt"
    remote_user: ec2-user
    register: init_finished
    until: "init_finished.stat.exists"
    retries: 15
    delay: 20

- name: Cleanup
  hosts: localhost
  gather_facts: false

  tasks:
  - name: Write ssm parameter
    community.aws.ssm_parameter:
      name: "/infrastructure/databases/{{ project_name }}-{{ function }}/volume_id"
      description: "volume id of {{ project_name }}-{{ function }} database instance"
      overwrite_value: "always"
      string_type: "SecureString"
      value: "{{ ec2_vol.volume_id }}"

  - name: terminate ec2 by instance id
    amazon.aws.ec2_instance:
      instance_ids: "{{ instance_id }}"
      region: "{{ region }}"
      state: "absent"

  - name: remove security group
    amazon.aws.ec2_security_group:
      name: "{{ ec2_sec_group.group_name }}"
      state: "absent"

  - name: remove postgres IAM role & instance profile
    community.aws.iam_role:
      name: "ansible-ebs-{{ project_name }}-{{ function }}-role"
      region: "{{ region }}"
      delete_instance_profile: yes
      purge_policies: yes
      state: "absent"

  - name: remove deployment policy
    amazon.aws.iam_managed_policy:
      policy_name: "ansible-ebs-{{ project_name }}-{{ function }}-policy"
      state: "absent"
...
